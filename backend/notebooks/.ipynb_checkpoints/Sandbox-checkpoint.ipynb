{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"auth_token\": \"b05572784a1a501cd117251ad5e7f596be7eb6a3\",\n",
    "    \"filters\": None,\n",
    "    \"currencies\": \"ETH\"\n",
    "}\n",
    "\n",
    "url = \"https://cryptopanic.com/api/posts/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6a372ce9978a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "r = requests.get(url, params=payload)\n",
    "print(r.url)\n",
    "a = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Newsflash: Ethereum Price Claws Its Way Back to $300 as Market Adds Billions\n",
      "https://cryptopanic.com/news/2825941/Newsflash-Ethereum-Price-Claws-Its-Way-Back-to-300-as-Market-Adds-Billions\n",
      "----------\n",
      "1: Ethereum Co-Founder Expects Another Crypto Bubble, Benefits Ecosystem\n",
      "https://cryptopanic.com/news/2825936/Ethereum-Co-Founder-Expects-Another-Crypto-Bubble-Benefits-Ecosystem\n",
      "----------\n",
      "2: Bitcoin Price recovers Amidst $15 Billion Cryptocurrency Market Bounce\n",
      "https://cryptopanic.com/news/2825874/Bitcoin-Price-recovers-Amidst-15-Billion-Cryptocurrency-Market-Bounce\n",
      "----------\n",
      "3: RT @ccneill: @VitalikButerin Russell Conjugations. See from @EricRWeinstein\n",
      "https://cryptopanic.com/news/2825666/RT-ccneill-VitalikButerin-Russell-Conjugations-See-from-EricRWeinstein\n",
      "----------\n",
      "4: 40 Ethereum Apps You Can Use Right Now – ConsenSys Media\n",
      "https://cryptopanic.com/news/2825660/40-Ethereum-Apps-You-Can-Use-Right-Now-ConsenSys-Media\n",
      "----------\n",
      "5: [Case Study] - Why Choose Ethereum to Build Your Project.\n",
      "https://cryptopanic.com/news/2824820/Case-Study-Why-Choose-Ethereum-to-Build-Your-Project\n",
      "----------\n",
      "6: Ethereum Founder and Coinbase CEO See Positive Growth in Crypto\n",
      "https://cryptopanic.com/news/2824631/Ethereum-Founder-and-Coinbase-CEO-See-Positive-Growth-in-Crypto\n",
      "----------\n",
      "7: Ethereum ($ETH) price is up <span class=\"color-green\">11.01%</span>\n",
      "https://cryptopanic.com/news/2824394/Ethereum-ETH-price-is-up-1101-in-the-last-24h\n",
      "----------\n",
      "8: Ethereum Classic (ETC) Finds Bottom At $10, Forms A Bullish Hammer Reversal Candlestick\n",
      "https://cryptopanic.com/news/2824410/Ethereum-Classic-ETC-Finds-Bottom-At-10-Forms-A-Bullish-Hammer-Reversal-Candlestick\n",
      "----------\n",
      "9: RT @mi_ayako: ETHSan Francisco hacker applications are now open! It will be all ETH month with Devcon and this!\n",
      "https://cryptopanic.com/news/2824138/RT-mi_ayako-ETHSan-Francisco-hacker-applications-are-now-open-It-will-be-all-ETH-month-with-Devcon-and-this\n",
      "----------\n",
      "10: ‘Sh*tcoin’ Ethereum Price Will Fall Below $100: BitMEX CEO\n",
      "https://cryptopanic.com/news/2823903/Shtcoin-Ethereum-Price-Will-Fall-Below-100-BitMEX-CEO\n",
      "----------\n",
      "11: Tezos , an Ethereum competitor\n",
      "https://cryptopanic.com/news/2823798/Tezos-an-Ethereum-competitor\n",
      "----------\n",
      "12: Technical Analysis – Buy when there is blood in the streets\n",
      "https://cryptopanic.com/news/2823607/Technical-Analysis-Buy-when-there-is-blood-in-the-streets\n",
      "----------\n",
      "13: Only 30% of Eth Transfers Are to Exchanges\n",
      "https://cryptopanic.com/news/2823460/Only-30-of-Eth-Transfers-Are-to-Exchanges\n",
      "----------\n",
      "14: Ropsten Testnet 51% Attack\n",
      "https://cryptopanic.com/news/2825907/Ropsten-Testnet-51-Attack\n",
      "----------\n",
      "15: Ethereum (ETH) is the Most Popular Cryptocurrency for Scammers, Kaspersky Report Shows\n",
      "https://cryptopanic.com/news/2823804/Ethereum-ETH-is-the-Most-Popular-Cryptocurrency-for-Scammers-Kaspersky-Report-Shows\n",
      "----------\n",
      "16: How it Feels putting Fiat into the Current Market\n",
      "https://cryptopanic.com/news/2823005/How-it-Feels-putting-Fiat-into-the-Current-Market\n",
      "----------\n",
      "17: 100,000 Genesis Eth Moved, Days Destroyed at Their Highest Since May\n",
      "https://cryptopanic.com/news/2822570/100000-Genesis-Eth-Moved-Days-Destroyed-at-Their-Highest-Since-May\n",
      "----------\n",
      "18: Which Cryptocurrencies Will Survive The Altcoin Apocalypse?\n",
      "https://cryptopanic.com/news/2822469/Which-Cryptocurrencies-Will-Survive-The-Altcoin-Apocalypse\n",
      "----------\n",
      "19: Bitcoin and Ethereum Rise 6% as Market Rebounds During Dark Skies\n",
      "https://cryptopanic.com/news/2822081/Bitcoin-and-Ethereum-Rise-6-as-Market-Rebounds-During-Dark-Skies\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for i, result in enumerate(a[\"results\"]):\n",
    "    title = result[\"title\"]\n",
    "    url = result[\"url\"]\n",
    "    print(f\"{i}: {title}\")\n",
    "    print(url)\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"SirSwiniak\"\n",
    "password = \"5tC^2ggxooWQ6Wg$\"\n",
    "secret = \"BwSQVeKzyDXPXajuWujsQJNGJfo\"\n",
    "app_id = \"Tx5kaavFynx7Nw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reddit = praw.Reddit(client_id=app_id,\n",
    "                     client_secret=secret,\n",
    "                     password=password,\n",
    "                     username=username,\n",
    "                     user_agent='My User Agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SirSwiniak\n"
     ]
    }
   ],
   "source": [
    "print(reddit.user.me())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask Anything Monday - Weekly Thread\n",
      "Learn python by contributing to pygame.\n",
      "Getting started with pygame (python 3)\n",
      "python timing script to click mouse\n",
      "Ip address changes\n",
      "What's the best way to parse this string?\n",
      "Two different variables point to the same address (but not always)?!\n",
      "Resource suggestions for flashcards?\n",
      "Program that estimates the impact on a website's traffic after performing an SEO task\n",
      "Newcomer looking for advice on a random two-word sentence generator!\n"
     ]
    }
   ],
   "source": [
    "for submission in reddit.subreddit('learnpython').hot(limit=10):\n",
    "    print(submission.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_name = \"CryptoCurrency\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit(subreddit_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transparency: Rep. Brad Sherman, who just told the Financial Services Committee he wants to prohibit Americans from buying and/or mining crypto, has a credit card processing company as largest campaign donor.\n",
      "----------\n",
      "This is the SEC Commissioner who wants the ETF approved. She has only 1700 followers. Lets show her some love from the Crypto Community.\n",
      "----------\n",
      "Rep. Brad Sherman sends a Twitter DM begging @TheCryptoDog to stop telling everyone about his biggest campaign donor being fined $13.3M for illegal gambling\n",
      "----------\n",
      "15 Year Old Kid Hacks John McAfee's 'Unhackable' Cryptocurrency Hardware Wallet! Plays DOOM on The Device\n",
      "----------\n",
      "Grandad was watching the news and hit me with this today\n",
      "----------\n",
      "Vitalik on Twitter: \"I think there's too much emphasis on BTC/ETH/whatever ETFs, and not enough emphasis on making it easier for people to buy $5 to $100 in cryptocurrency via cards at corner stores.\" Personally, I think both are necessary & we need to make crypto more accessible. What do you think?\n",
      "----------\n",
      "You Can't Ban Math: Crypto Unites to Call Out Clueless Congressman who wants to ban Cryptos\n",
      "----------\n",
      "90 % is accurate 😆\n",
      "----------\n",
      "Dreams come true - Someone thanks Satoshi here in Mykonos ;)\n",
      "----------\n",
      "The owner of the New York Stock Exchange is teaming up with Microsoft and Starbucks to build an 'ecosystem' for crypto\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for submission in subreddit.top(limit=10, time_filter=\"month\"):\n",
    "    print(submission.title)\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0): +0 -0\n",
      "2018-08-17 22:31:36\n",
      "https://www.reddit.com/r/CryptoCurrency/comments/981v5e/what_is_going_out_with_cryptos_this_am/\n",
      "981v5e\n",
      "What is going out with Cryptos this AM: Cryptocurrencies are bouncing back from yesterday’s late day slide as Bitcoin Cash futures are set to start trading on Crypto Facilities platform at 11am EST\n",
      "----------\n",
      "(0): +0 -0\n",
      "2018-08-17 22:28:54\n",
      "https://coinfrenzy.io/exchanges-not-ready-bull-market/\n",
      "981ui5\n",
      "Exchanges Might not be Ready for a Bull Market\n",
      "----------\n",
      "(4): +4 -0\n",
      "2018-08-17 22:19:16\n",
      "https://www.chepicap.com/en/news/2987/strong-usd-affecting-crypto-markets-says-etoro-analyst.html\n",
      "981s7q\n",
      "Strong US Dollar affecting crypto markets, says eToro analyst\n",
      "----------\n",
      "(2): +2 -0\n",
      "2018-08-17 22:07:22\n",
      "https://blog.iota.org/beta-version-of-our-new-javascript-library-iota-js-out-now-cd9bc9e2e1c1\n",
      "981pgp\n",
      "Beta version of the new JavaScript library, IOTA.JS is out now\n",
      "----------\n",
      "(2): +2 -0\n",
      "2018-08-17 21:36:28\n",
      "https://bcfocus.com/news/ripple-fundstrat-nobel-laureate-paul-krugman-share-stage-to-deliberate-on-crypto-future/21101/\n",
      "981iqv\n",
      "Ripple, Fundstrat & Nobel Laureate Paul Krugman share stage to deliberate on crypto future\n",
      "----------\n",
      "(0): +0 -0\n",
      "2018-08-17 21:22:19\n",
      "https://www.reddit.com/r/nanocurrency/comments/97yjms/to_my_friends_in_the_nano_community/\n",
      "981fx5\n",
      "DataDash continues to show his love for Nano with this lovely, well written post\n",
      "----------\n",
      "(1): +1 -0\n",
      "2018-08-17 20:46:00\n",
      "https://medium.com/coinmirror-co/a-dapp-walkthrough-with-coinmirror-55cc027b3816\n",
      "9818o8\n",
      "What Are DApps And How Can You Use Them Conveniently? A Walkthrough With CoinMirror\n",
      "----------\n",
      "(2): +2 -0\n",
      "2018-08-17 20:35:45\n",
      "https://cryptotrader.news/category/acchain/\n",
      "9816t1\n",
      "Consumers Have Lost Almost $100 Million To ICO Exit Scams\n",
      "----------\n",
      "(8): +8 -0\n",
      "2018-08-17 20:29:42\n",
      "https://www.youtube.com/watch?v=o5K0J7JIJbw\n",
      "9815pw\n",
      "Utrum - Your Crypto Playbook - Intro\n",
      "----------\n",
      "(11): +11 -0\n",
      "2018-08-17 20:17:08\n",
      "https://medium.com/proxeus/carry-your-world-in-your-pocket-8475fb8d3417\n",
      "9813aa\n",
      "The Swiss solution to data storage, and it’s even better than their watches\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "flair = \"General-News\"\n",
    "search_query = f\"flair:{flair}\"\n",
    "\n",
    "for submission in subreddit.search(query=search_query, sort=\"new\", limit=10):\n",
    "    print(f\"({submission.score}): +{submission.ups} -{submission.downs}\")\n",
    "    print(datetime.fromtimestamp(submission.created))\n",
    "    print(submission.url)\n",
    "    print(submission.id)\n",
    "    print(submission.title)\n",
    "#     print(dir(submission))\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-03-12 06:51:50\n"
     ]
    }
   ],
   "source": [
    "creation_date = datetime.fromtimestamp(subreddit.created)\n",
    "print(creation_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1): +1 -0\n",
      "2018-08-18 00:45:25\n",
      "https://twitter.com/kerooke/status/1030459469052825601\n",
      "982uia\n",
      "Polymath tokenizes $210 million of equity! Security tokens are starting to make serious moves\n",
      "----------\n",
      "(1): +1 -0\n",
      "2018-08-18 00:12:18\n",
      "https://www.chepicap.com/en/news/2988/major-altcoin-gains-vechain-up-47-percent-nano-increases-47-cortex-over-70-up.html\n",
      "982lab\n",
      "Major altcoin gains: VeChain up 47 percent, Nano increases 47%, Cortex over 70% up\n",
      "----------\n",
      "(10): +10 -0\n",
      "2018-08-18 00:05:48\n",
      "https://mp.weixin.qq.com/s?__biz=MzU2MjE1MTMwMQ==&mid=2247484921&idx=2&sn=6d4fddbd2713de4b13c1f6542bf22da1&chksm=fc6caf13cb1b2605ad1a426037f6e40d07d009aaab1cc0f4d1499fe5b1beb60ab941cc19a8f0&mpshare=1&scene=1&srcid=08176WDjgNMwCpjdDuGU6cOn#rd\n",
      "982jh3\n",
      "Chinese Valentine's Day\n",
      "----------\n",
      "(4): +4 -0\n",
      "2018-08-17 23:45:19\n",
      "https://i.redd.it/nfgwcyhxqng11.png\n",
      "982drp\n",
      "Japanese retail investor dump lira, cutting positions by half\n",
      "----------\n",
      "(0): +0 -0\n",
      "2018-08-17 23:28:50\n",
      "https://medium.com/@shaynek980/why-you-probably-havent-heard-of-ambrosus-yet-but-really-should-1aa9cc695447\n",
      "9829g0\n",
      "Why You Probably Haven’t Heard of Ambrosus yet, but Really Should\n",
      "----------\n",
      "(0): +0 -0\n",
      "2018-08-17 23:15:18\n",
      "https://www.livebitcoinnews.com/producers-preview-cryptocurrency-movie-crypto/\n",
      "982627\n",
      "Cryptocurrencies are coming to the Big Screen 🎬\n",
      "----------\n",
      "(0): +0 -0\n",
      "2018-08-17 23:04:54\n",
      "http://icofriends.com/cryptocurrency-will-influence-us-business/\n",
      "9823gl\n",
      "How Cryptocurrency Will Influence US Business\n",
      "----------\n",
      "(9): +9 -0\n",
      "2018-08-17 23:03:00\n",
      "https://www.investinblockchain.com/omisego-request-network-complementary/\n",
      "9822xx\n",
      "I think OmiseGO and Request Network can work very well together. Not competitive at all.\n",
      "----------\n",
      "(0): +0 -0\n",
      "2018-08-17 22:31:36\n",
      "https://www.reddit.com/r/CryptoCurrency/comments/981v5e/what_is_going_out_with_cryptos_this_am/\n",
      "981v5e\n",
      "What is going out with Cryptos this AM: Cryptocurrencies are bouncing back from yesterday’s late day slide as Bitcoin Cash futures are set to start trading on Crypto Facilities platform at 11am EST\n",
      "----------\n",
      "(0): +0 -0\n",
      "2018-08-17 22:28:54\n",
      "https://coinfrenzy.io/exchanges-not-ready-bull-market/\n",
      "981ui5\n",
      "Exchanges Might not be Ready for a Bull Market\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "flair = \"General-News\"\n",
    "# search_query = f\"flair:{flair} timestamp:1465171200..1467763200\"\n",
    "search_query = f\"flair:{flair}\"\n",
    "\n",
    "for submission in subreddit.search(query=search_query, sort=\"new\", syntax=\"cloudsearch\", limit=10):\n",
    "    print(f\"({submission.score}): +{submission.ups} -{submission.downs}\")\n",
    "    print(datetime.fromtimestamp(submission.created))\n",
    "    print(submission.url)\n",
    "    print(submission.id)\n",
    "    print(submission.title)\n",
    "#     print(dir(submission))\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Subreddit' object has no attribute 'submissions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-7351df865a61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msubmission\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubreddit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmissions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1485796660\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1517332671\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"OK\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\moje pliki\\programy\\.python_envs\\cryptochart_backend\\lib\\site-packages\\praw\\models\\reddit\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attribute)\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         raise AttributeError('{!r} object has no attribute {!r}'\n\u001b[1;32m---> 41\u001b[1;33m                              .format(self.__class__.__name__, attribute))\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Subreddit' object has no attribute 'submissions'"
     ]
    }
   ],
   "source": [
    "for submission in subreddit.submissions(1485796660, 1517332671):\n",
    "    print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MESSAGE_PREFIX',\n",
       " 'STR_FIELD',\n",
       " 'VALID_TIME_FILTERS',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_banned',\n",
       " '_comments',\n",
       " '_contributor',\n",
       " '_create_or_update',\n",
       " '_emoji',\n",
       " '_fetch',\n",
       " '_fetched',\n",
       " '_filters',\n",
       " '_flair',\n",
       " '_info_params',\n",
       " '_info_path',\n",
       " '_mod',\n",
       " '_moderator',\n",
       " '_modmail',\n",
       " '_muted',\n",
       " '_path',\n",
       " '_quarantine',\n",
       " '_reddit',\n",
       " '_reset_attributes',\n",
       " '_safely_add_arguments',\n",
       " '_stream',\n",
       " '_stylesheet',\n",
       " '_submission_class',\n",
       " '_subreddit_list',\n",
       " '_url_parts',\n",
       " '_validate_time_filter',\n",
       " '_widgets',\n",
       " '_wiki',\n",
       " 'accounts_active',\n",
       " 'accounts_active_is_fuzzed',\n",
       " 'active_user_count',\n",
       " 'advertiser_category',\n",
       " 'all_original_content',\n",
       " 'allow_discovery',\n",
       " 'allow_images',\n",
       " 'allow_videogifs',\n",
       " 'allow_videos',\n",
       " 'audience_target',\n",
       " 'banned',\n",
       " 'banner_background_color',\n",
       " 'banner_background_image',\n",
       " 'banner_img',\n",
       " 'banner_size',\n",
       " 'can_assign_link_flair',\n",
       " 'can_assign_user_flair',\n",
       " 'collapse_deleted_comments',\n",
       " 'comment_score_hide_mins',\n",
       " 'comments',\n",
       " 'community_icon',\n",
       " 'contributor',\n",
       " 'controversial',\n",
       " 'created',\n",
       " 'created_utc',\n",
       " 'description',\n",
       " 'description_html',\n",
       " 'display_name',\n",
       " 'display_name_prefixed',\n",
       " 'emoji',\n",
       " 'emojis_enabled',\n",
       " 'filters',\n",
       " 'flair',\n",
       " 'fullname',\n",
       " 'gilded',\n",
       " 'has_menu_widget',\n",
       " 'header_img',\n",
       " 'header_size',\n",
       " 'header_title',\n",
       " 'hide_ads',\n",
       " 'hot',\n",
       " 'icon_img',\n",
       " 'icon_size',\n",
       " 'id',\n",
       " 'is_enrolled_in_new_modmail',\n",
       " 'key_color',\n",
       " 'lang',\n",
       " 'link_flair_enabled',\n",
       " 'link_flair_position',\n",
       " 'message',\n",
       " 'mod',\n",
       " 'moderator',\n",
       " 'modmail',\n",
       " 'muted',\n",
       " 'name',\n",
       " 'new',\n",
       " 'notification_level',\n",
       " 'original_content_tag_enabled',\n",
       " 'over18',\n",
       " 'parse',\n",
       " 'primary_color',\n",
       " 'public_description',\n",
       " 'public_description_html',\n",
       " 'public_traffic',\n",
       " 'quaran',\n",
       " 'quarantine',\n",
       " 'random',\n",
       " 'random_rising',\n",
       " 'rising',\n",
       " 'rules',\n",
       " 'search',\n",
       " 'show_media',\n",
       " 'show_media_preview',\n",
       " 'spoilers_enabled',\n",
       " 'sticky',\n",
       " 'stream',\n",
       " 'stylesheet',\n",
       " 'submission_type',\n",
       " 'submit',\n",
       " 'submit_link_label',\n",
       " 'submit_text',\n",
       " 'submit_text_html',\n",
       " 'submit_text_label',\n",
       " 'subreddit_type',\n",
       " 'subscribe',\n",
       " 'subscribers',\n",
       " 'suggested_comment_sort',\n",
       " 'title',\n",
       " 'top',\n",
       " 'traffic',\n",
       " 'unsubscribe',\n",
       " 'url',\n",
       " 'user_can_flair_in_sr',\n",
       " 'user_flair_background_color',\n",
       " 'user_flair_css_class',\n",
       " 'user_flair_enabled_in_sr',\n",
       " 'user_flair_position',\n",
       " 'user_flair_richtext',\n",
       " 'user_flair_template_id',\n",
       " 'user_flair_text',\n",
       " 'user_flair_text_color',\n",
       " 'user_flair_type',\n",
       " 'user_has_favorited',\n",
       " 'user_is_banned',\n",
       " 'user_is_contributor',\n",
       " 'user_is_moderator',\n",
       " 'user_is_muted',\n",
       " 'user_is_subscriber',\n",
       " 'user_sr_flair_enabled',\n",
       " 'user_sr_theme_enabled',\n",
       " 'videostream_links_count',\n",
       " 'whitelist_status',\n",
       " 'widgets',\n",
       " 'wiki',\n",
       " 'wiki_enabled',\n",
       " 'wls']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Only?\n",
      "False\n",
      "\n",
      "\n",
      "Enter year start2016\n",
      "Enter Month start10\n",
      "Enter Day start10\n",
      "Enter year end2016\n",
      "Enter Month end12\n",
      "Enter Day end12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching: GET https://oauth.reddit.com/r/science/search/\n",
      "Fetching: GET https://oauth.reddit.com/r/science/search/\n",
      "Fetching: GET https://oauth.reddit.com/r/science/search/\n",
      "Data: None\n",
      "Data: None\n",
      "Data: None\n",
      "Params: {'q': 'title:cats timestamp:1476050400..1481497200', 'restrict_sr': True, 'sort': 'relevance', 'syntax': 'cloudsearch', 't': 'all', 'limit': 1024, 'raw_json': 1}\n",
      "Params: {'q': 'title:cats timestamp:1476050400..1481497200', 'restrict_sr': True, 'sort': 'relevance', 'syntax': 'cloudsearch', 't': 'all', 'limit': 1024, 'raw_json': 1}\n",
      "Params: {'q': 'title:cats timestamp:1476050400..1481497200', 'restrict_sr': True, 'sort': 'relevance', 'syntax': 'cloudsearch', 't': 'all', 'limit': 1024, 'raw_json': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1476050400\n",
      "1481497200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Response: 503 (48 bytes)\n",
      "Response: 503 (48 bytes)\n",
      "Response: 503 (48 bytes)\n",
      "Retrying due to 503 status: GET https://oauth.reddit.com/r/science/search/\n",
      "Retrying due to 503 status: GET https://oauth.reddit.com/r/science/search/\n",
      "Retrying due to 503 status: GET https://oauth.reddit.com/r/science/search/\n",
      "Sleeping: 0.48 seconds prior to retry\n",
      "Sleeping: 0.48 seconds prior to retry\n",
      "Sleeping: 0.48 seconds prior to retry\n",
      "Fetching: GET https://oauth.reddit.com/r/science/search/\n",
      "Fetching: GET https://oauth.reddit.com/r/science/search/\n",
      "Fetching: GET https://oauth.reddit.com/r/science/search/\n",
      "Data: None\n",
      "Data: None\n",
      "Data: None\n",
      "Params: {'q': 'title:cats timestamp:1476050400..1481497200', 'restrict_sr': True, 'sort': 'relevance', 'syntax': 'cloudsearch', 't': 'all', 'limit': 1024, 'raw_json': 1}\n",
      "Params: {'q': 'title:cats timestamp:1476050400..1481497200', 'restrict_sr': True, 'sort': 'relevance', 'syntax': 'cloudsearch', 't': 'all', 'limit': 1024, 'raw_json': 1}\n",
      "Params: {'q': 'title:cats timestamp:1476050400..1481497200', 'restrict_sr': True, 'sort': 'relevance', 'syntax': 'cloudsearch', 't': 'all', 'limit': 1024, 'raw_json': 1}\n",
      "Response: 503 (48 bytes)\n",
      "Response: 503 (48 bytes)\n",
      "Response: 503 (48 bytes)\n",
      "Retrying due to 503 status: GET https://oauth.reddit.com/r/science/search/\n",
      "Retrying due to 503 status: GET https://oauth.reddit.com/r/science/search/\n",
      "Retrying due to 503 status: GET https://oauth.reddit.com/r/science/search/\n",
      "Sleeping: 2.11 seconds prior to retry\n",
      "Sleeping: 2.11 seconds prior to retry\n",
      "Sleeping: 2.11 seconds prior to retry\n",
      "Fetching: GET https://oauth.reddit.com/r/science/search/\n",
      "Fetching: GET https://oauth.reddit.com/r/science/search/\n",
      "Fetching: GET https://oauth.reddit.com/r/science/search/\n",
      "Data: None\n",
      "Data: None\n",
      "Data: None\n",
      "Params: {'q': 'title:cats timestamp:1476050400..1481497200', 'restrict_sr': True, 'sort': 'relevance', 'syntax': 'cloudsearch', 't': 'all', 'limit': 1024, 'raw_json': 1}\n",
      "Params: {'q': 'title:cats timestamp:1476050400..1481497200', 'restrict_sr': True, 'sort': 'relevance', 'syntax': 'cloudsearch', 't': 'all', 'limit': 1024, 'raw_json': 1}\n",
      "Params: {'q': 'title:cats timestamp:1476050400..1481497200', 'restrict_sr': True, 'sort': 'relevance', 'syntax': 'cloudsearch', 't': 'all', 'limit': 1024, 'raw_json': 1}\n",
      "Response: 503 (48 bytes)\n",
      "Response: 503 (48 bytes)\n",
      "Response: 503 (48 bytes)\n"
     ]
    },
    {
     "ename": "ServerError",
     "evalue": "received 503 HTTP response",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mServerError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-47c690bc3e90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;31m# This loops through search results and writes them in the open HTML file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msubmission\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearchstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relevance'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msyntax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cloudsearch'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[0mfile_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"<h2>{}</h2>\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mfile_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"<p>Author: {}</p>\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauthor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\moje pliki\\programy\\.python_envs\\cryptochart_backend\\lib\\site-packages\\praw\\models\\listing\\generator.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_listing\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_list_index\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_listing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_list_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\moje pliki\\programy\\.python_envs\\cryptochart_backend\\lib\\site-packages\\praw\\models\\listing\\generator.py\u001b[0m in \u001b[0;36m_next_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_listing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reddit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_listing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_listing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_listing\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# for submission duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\moje pliki\\programy\\.python_envs\\cryptochart_backend\\lib\\site-packages\\praw\\reddit.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, path, params)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \"\"\"\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GET'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_objector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjectify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\moje pliki\\programy\\.python_envs\\cryptochart_backend\\lib\\site-packages\\praw\\reddit.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, path, params, data, files)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \"\"\"\n\u001b[0;32m    505\u001b[0m         return self._core.request(method, path, data=data, files=files,\n\u001b[1;32m--> 506\u001b[1;33m                                   params=params)\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     def submission(  # pylint: disable=invalid-name,redefined-builtin\n",
      "\u001b[1;32me:\\moje pliki\\programy\\.python_envs\\cryptochart_backend\\lib\\site-packages\\prawcore\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, path, data, files, json, params)\u001b[0m\n\u001b[0;32m    183\u001b[0m         return self._request_with_retries(\n\u001b[0;32m    184\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             params=params, url=url)\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\moje pliki\\programy\\.python_envs\\cryptochart_backend\\lib\\site-packages\\prawcore\\sessions.py\u001b[0m in \u001b[0;36m_request_with_retries\u001b[1;34m(self, data, files, json, method, params, url, retries)\u001b[0m\n\u001b[0;32m    126\u001b[0m                             response.status_code in self.RETRY_STATUSES):\n\u001b[0;32m    127\u001b[0m             return self._do_retry(data, files, json, method, params, response,\n\u001b[1;32m--> 128\u001b[1;33m                                   retries, saved_exception, url)\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTATUS_EXCEPTIONS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTATUS_EXCEPTIONS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\moje pliki\\programy\\.python_envs\\cryptochart_backend\\lib\\site-packages\\prawcore\\sessions.py\u001b[0m in \u001b[0;36m_do_retry\u001b[1;34m(self, data, files, json, method, params, response, retries, saved_exception, url)\u001b[0m\n\u001b[0;32m     92\u001b[0m         return self._request_with_retries(\n\u001b[0;32m     93\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             params=params, url=url, retries=retries - 1)\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\moje pliki\\programy\\.python_envs\\cryptochart_backend\\lib\\site-packages\\prawcore\\sessions.py\u001b[0m in \u001b[0;36m_request_with_retries\u001b[1;34m(self, data, files, json, method, params, url, retries)\u001b[0m\n\u001b[0;32m    126\u001b[0m                             response.status_code in self.RETRY_STATUSES):\n\u001b[0;32m    127\u001b[0m             return self._do_retry(data, files, json, method, params, response,\n\u001b[1;32m--> 128\u001b[1;33m                                   retries, saved_exception, url)\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTATUS_EXCEPTIONS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTATUS_EXCEPTIONS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\moje pliki\\programy\\.python_envs\\cryptochart_backend\\lib\\site-packages\\prawcore\\sessions.py\u001b[0m in \u001b[0;36m_do_retry\u001b[1;34m(self, data, files, json, method, params, response, retries, saved_exception, url)\u001b[0m\n\u001b[0;32m     92\u001b[0m         return self._request_with_retries(\n\u001b[0;32m     93\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             params=params, url=url, retries=retries - 1)\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\moje pliki\\programy\\.python_envs\\cryptochart_backend\\lib\\site-packages\\prawcore\\sessions.py\u001b[0m in \u001b[0;36m_request_with_retries\u001b[1;34m(self, data, files, json, method, params, url, retries)\u001b[0m\n\u001b[0;32m    128\u001b[0m                                   retries, saved_exception, url)\n\u001b[0;32m    129\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTATUS_EXCEPTIONS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTATUS_EXCEPTIONS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'no_content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mServerError\u001b[0m: received 503 HTTP response"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import datetime\n",
    "from time import mktime\n",
    "import logging\n",
    "\n",
    "# This is basic logging code provided by PRAW.  I didn't really alter anything\n",
    "# here, so I don't have too much to comment on\n",
    "handler = logging.StreamHandler()\n",
    "handler.setLevel(logging.DEBUG)\n",
    "logger = logging.getLogger('prawcore')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Here's the initialization of the 'Reddit' object.  Client ID and secret\n",
    "# are given Reddit's app authorization (see the \"Resources\" section on the readme).\n",
    "# The user agent is a string that gives reddit basic information on what you're doing.\n",
    "# It doesn't really need to follow a strict syntax, but try to make something similar \n",
    "\n",
    "# TODO: Replace 'id' and 'secret' with th id and secret that you got from Reddit's app auth\n",
    "# TODO: Type in password and username or delete fields (deleting those is acceptable for read-\n",
    "#       only applications, which this is by default.\n",
    "# TODO: Create user_agent string that is of similar form and reasonably descriptive\n",
    "reddit = praw.Reddit(client_id=app_id,\n",
    "                     client_secret=secret,\n",
    "                     password=password,\n",
    "                     username=username,\n",
    "                     user_agent='windows:com.example.datestamp_search:v0.0.1 (by /u/wulffguy)')\n",
    "\n",
    "# This is just printing out whether you're in read only mode or not\n",
    "print(\"Read Only?\")\n",
    "print(reddit.read_only)\n",
    "print(\"\\n\")\n",
    "\n",
    "#print(reddit.user.me())\n",
    "\n",
    "# The way my code works is it takes a date range as a console input and prints\n",
    "# out all the search results as a basically formatted HTML page\n",
    "# Since I've been the only one using it thus far, it's a bit messy\n",
    "\n",
    "# This initializes the subreddit you'd like to search through.  I haven't tried\n",
    "# it, but I believe that 'all' works as a valid sub if you want to search /r/all\n",
    "# TODO: Replace \"science\" with a different sub\n",
    "sub = reddit.subreddit(\"science\")\n",
    "\n",
    "# Here's where the Python console takes inputs for date and converts them into\n",
    "# int data types\n",
    "year_s = int(input(\"Enter year start\"))\n",
    "month_s = int(input(\"Enter Month start\"))\n",
    "day_s = int(input(\"Enter Day start\"))\n",
    "\n",
    "year_e = int(input(\"Enter year end\"))\n",
    "month_e = int(input(\"Enter Month end\"))\n",
    "day_e = int(input(\"Enter Day end\"))\n",
    "\n",
    "# This creates/opens a file with string formatting as follows\n",
    "file_out = open(\"{}_{}{}{}_{}{}{}.html\".format(sub, year_s, month_s, day_s, year_e, month_e, day_e),\"w\")\n",
    "\n",
    "# This converts the date values to unix-accepted values\n",
    "start = datetime.date(year_s,month_s,day_s)\n",
    "start = int(mktime(start.timetuple()))\n",
    "print(start)\n",
    "\n",
    "end = datetime.date(year_e,month_e,day_e)\n",
    "end = int(mktime(end.timetuple()))\n",
    "print(end)\n",
    "\n",
    "# Here's the search string.  I'm interested in things involving rule changes on\n",
    "# subs, so I put that in here.\n",
    "# TODO: Replace 'rule' with your own search string. Don't get rid of the timestamp part\n",
    "searchstr = \"title:cats timestamp:{}..{}\".format(start,end)\n",
    "\n",
    "# This loops through search results and writes them in the open HTML file\n",
    "for submission in sub.search(searchstr,sort='relevance',syntax='cloudsearch',limit=None):\n",
    "    file_out.write(\"<h2>{}</h2>\\n\".format(submission.title))\n",
    "    file_out.write(\"<p>Author: {}</p>\\n\".format(submission.author))\n",
    "    file_out.write(\"<p>Comments: {}</p>\\n\".format(submission.num_comments))\n",
    "    file_out.write(\"<p>Timestamp: {}</p>\\n\".format(submission.created))\n",
    "    file_out.write(\"<p>URL: <a href=\\\"{}\\\">{}</a></p>\\n\\n\".format(submission.url,submission.url))\n",
    "    \n",
    "file_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cdr%3A1%2CCcd_min%3A1%2F1%2F2000%2CCcd_max%3A1%2F1%2F2001'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_string = \"cdr:1,Ccd_min:1/1/2000,Ccd_max:1/1/2001\"\n",
    "urllib.parse.quote_plus(date_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-72-83ea38327b08>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-72-83ea38327b08>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    cdr%3A1%2Ccd_min%3A1%2F1%2F2000%2Ccd_max%3A1%2F1%2F2001\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "cdr%3A1%2Ccd_min%3A1%2F1%2F2000%2Ccd_max%3A1%2F1%2F2001\n",
    "cdr%3A1%2CCcd_min%3A1%2F1%2F2000%2CCcd_max%3A1%2F1%2F2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cssselect\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/44/25b7283e50585f0b4156960691d951b05d061abf4a714078393e51929b30/cssselect-1.0.3-py2.py3-none-any.whl\n",
      "Installing collected packages: cssselect\n",
      "Successfully installed cssselect-1.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install cssselect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from lxml import html\n",
    "from lxml.cssselect import CSSSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"bitcoin\"\n",
    "search_type = \"nws\"\n",
    "start_date = \"1/1/2016\"\n",
    "end_date = \"1/2/2016\"\n",
    "custom_date_range = f\"cdr:1,cd_min:{start_date},cd_max:{end_date}\"\n",
    "payload = {\n",
    "    \"q\" : query,\n",
    "    \"tbs\": custom_date_range,\n",
    "    \"tbm\": search_type\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:61.0) Gecko/20100101 Firefox/61.0\",\n",
    "    \"Accept-Language\": \"pl,en-US;q=0.7,en;q=0.3\"\n",
    "}\n",
    "\n",
    "search_url = \"https://www.google.com/search\"\n",
    "\n",
    "r = requests.get(search_url, params=payload, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com/search?q=bitcoin&tbs=cdr%3A1%2Ccd_min%3A1%2F1%2F2016%2Ccd_max%3A1%2F2%2F2016&tbm=nws\n",
      "Generated url is correct? True\n"
     ]
    }
   ],
   "source": [
    "print(r.url)\n",
    "correct_url = \"https://www.google.com/search?q=bitcoin&tbs=cdr%3A1%2Ccd_min%3A1%2F1%2F2016%2Ccd_max%3A1%2F2%2F2016&tbm=nws\"\n",
    "print(f\"Generated url is correct? {r.url == correct_url}\")\n",
    "print(r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.8 ms ± 1.3 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Lxml\n",
    "search_page_source = html.fromstring(r.content)\n",
    "\n",
    "all_news_on_page_selector = CSSSelector(\"div.g\")\n",
    "\n",
    "all_news_on_page = all_news_on_page_selector(search_page_source)\n",
    "\n",
    "selectors = {\n",
    "    \"title\": CSSSelector(\".l.lLrAF\"),\n",
    "    \"summary\": CSSSelector(\"div.st\"),\n",
    "    \"date\": CSSSelector(\".f.nsa.fwzPFf\"),\n",
    "    \"source\": CSSSelector(\".xQ82C.e8fRJf\"),\n",
    "    \"source_url\": CSSSelector(\".top.NQHJEb.dfhHve\"),\n",
    "    \"image_url\": CSSSelector(\"img.th.BbeB2d\")\n",
    "}\n",
    "\n",
    "for index, news in enumerate(all_news_on_page):\n",
    "    if index == 0:\n",
    "        # Pierwszy news ma inny typ (ale podobny)\n",
    "        continue\n",
    "        \n",
    "    title = selectors[\"title\"](news).pop().text_content()\n",
    "    content = selectors[\"summary\"](news).pop().text_content()\n",
    "    date = selectors[\"date\"](news).pop().text_content()\n",
    "    \n",
    "#     print(f\"Date: {date}\")\n",
    "#     print(title)\n",
    "#     print(content)\n",
    "#     print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.8 ms ± 5.75 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# BS4\n",
    "search_page_source = BeautifulSoup(r.text, 'lxml')\n",
    "all_news_on_page = search_page_source.select(\"div.g\")\n",
    "\n",
    "for index, news in enumerate(all_news_on_page):\n",
    "    if index == 0:\n",
    "        # Pierwszy news ma inny typ (ale podobny)\n",
    "        continue\n",
    "    title = news.select(\".l.lLrAF\").pop().get_text()\n",
    "    content = news.select(\"div.st\").pop().get_text()\n",
    "    date = news.select(\".f.nsa.fwzPFf\").pop().get_text()\n",
    "#     print(f\"Date: {date}\")\n",
    "#     print(title)\n",
    "#     print(content)\n",
    "#     print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
